version: '3.8'

# # ç¯å¢ƒå˜é‡é…ç½®
# env_file:
#   - vllm-config.env

services:
  # Traefikåå‘ä»£ç†æœåŠ¡
  traefik:
    image: traefik:v3.0
    container_name: TRAEFIK_PROXY
    security_opt:
      - no-new-privileges:true
    command:
      # APIå’Œä»ªè¡¨æ¿é…ç½®
      - --api.dashboard=true
      - --api.insecure=true
      # Pingç«¯ç‚¹é…ç½®ï¼ˆç”¨äºå¥åº·æ£€æŸ¥ï¼‰
      - --ping=true
      # å…¥å£ç‚¹é…ç½®
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      # è‡ªåŠ¨HTTPSé‡å®šå‘
      - --entrypoints.web.http.redirections.entrypoint.to=websecure
      - --entrypoints.web.http.redirections.entrypoint.scheme=https
      # Dockeræä¾›è€…é…ç½®
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --providers.docker.network=ai-services
      # æ–‡ä»¶æä¾›è€…é…ç½®ï¼ˆåŠ¨æ€é…ç½®ï¼‰
      - --providers.file.filename=/etc/traefik/dynamic.yml
      - --providers.file.watch=true
      # è¯ä¹¦è§£æå™¨é…ç½®ï¼ˆå¯é€‰ï¼Œç”¨äºLet's Encryptï¼‰

      - --certificatesresolvers.letsencrypt.acme.dnschallenge=true
      - --certificatesresolvers.letsencrypt.acme.dnschallenge.provider=alidns
      - --certificatesresolvers.letsencrypt.acme.email=744204541@qq.com  # ğŸ”¥ ç”¨ä½ çš„QQé‚®ç®±
      - --certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json
      # æ—¥å¿—é…ç½®
      - --log.level=INFO
      - --accesslog=true
      - --accesslog.filepath=/var/log/traefik/access.log
      - --accesslog.format=json
      # PrometheusæŒ‡æ ‡é…ç½®
      - --metrics.prometheus=true
      - --metrics.prometheus.addEntryPointsLabels=true
      - --metrics.prometheus.addServicesLabels=true
      - --metrics.prometheus.addRoutersLabels=true
    ports:
      - "8000:80"   # HTTP (é¿å…ä¸Apacheå†²çª)
      - "8443:443"  # HTTPS 
      - "8080:8080" # Traefikä»ªè¡¨æ¿
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik/letsencrypt:/letsencrypt
      - ./traefik/logs:/var/log/traefik
      - ./traefik/dynamic.yml:/etc/traefik/dynamic.yml:ro
    environment:
      # !!! å°† YOUR_ALICLOUD_ACCESS_KEY_ID æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® AccessKey ID !!!
      - ALICLOUD_ACCESS_KEY=
      # !!! å°† YOUR_ALICLOUD_ACCESS_KEY_SECRET æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® AccessKey Secret !!!
      - ALICLOUD_SECRET_KEY=
    networks:
      - ai-services
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "traefik healthcheck --ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "traefik.enable=true"
      # ğŸ”¥ ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„åŸŸåå’ŒHTTPS
      - "traefik.http.routers.traefik-https.rule=Host(`xkb.744204541.xyz`) || PathPrefix(`/traefik`)"
      - "traefik.http.routers.traefik-https.entrypoints=websecure"
      - "traefik.http.routers.traefik-https.tls=true"
      - "traefik.http.routers.traefik-https.service=api@internal"  # ğŸ”¥ ä½¿ç”¨å†…éƒ¨APIæœåŠ¡
      # ğŸ”¥ ä½¿ç”¨è®¤è¯ä¸­é—´ä»¶
      - "traefik.http.routers.traefik-https.middlewares=protected-admin"
      
      # ğŸ”¥ å¯é€‰ï¼šåŒæ—¶æ”¯æŒHTTPé‡å®šå‘
      - "traefik.http.routers.traefik-http.rule=Host(`xkb.744204541.xyz`) || PathPrefix(`/traefik`)"
      - "traefik.http.routers.traefik-http.entrypoints=web"
      - "traefik.http.routers.traefik-http.middlewares=redirect-to-https"

  # STTè¯­éŸ³è½¬æ–‡æœ¬æœåŠ¡ - åŸºäºfaster-whisperç›®å½•
  stt-service:
    build: 
      context: ./stt-service
      dockerfile: Dockerfile
    container_name: STT_55001
    ports:
      - "55001:9000"
    environment:
      - MODEL_SIZE=large-v3
      - PORT=9000
      - CUDA_VISIBLE_DEVICES=0   # ç”¨GPU 0
      - FASTAPI_ROOT_PATH=/stt  # è®¾ç½®FastAPIæ ¹è·¯å¾„
      # - HTTPS_PROXY=http://192.168.2.222:1080
      # - HTTP_PROXY=http://192.168.2.222:1080
    volumes:
      # æ¨¡å‹æ–‡ä»¶æŒ‚è½½ - ä½¿ç”¨æœ¬åœ°large-v3æ¨¡å‹
      - ./stt-service/large-v3:/app/large-v3:ro
      - ./models/whisper:/tmp/faster_whisper
      - ./shared-data:/app/shared
      - ./stt-service/test_audio:/app/test_audio:ro
    deploy:
      resources:
        reservations: #é¢„ç•™èµ„æºï¼Œç¡®ä¿æœåŠ¡è‡³å°‘èƒ½è·å¾—è¿™äº›èµ„æºã€‚
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        # limits: #é™åˆ¶èµ„æºä½¿ç”¨ï¼Œç¡®ä¿æœåŠ¡ä¸ä¼šè¶…å‡ºè¿™äº›é™åˆ¶ã€‚
        #   memory: 8G
        #   cpus: '4'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/stt/health"] 
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s  # å¢åŠ å¯åŠ¨æ—¶é—´ï¼Œå› ä¸ºéœ€è¦åŠ è½½å¤§æ¨¡å‹
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      # === 1. HTTPS è·¯ç”±ï¼šå®é™…å¤„ç†è¯·æ±‚ ===
      - "traefik.http.routers.stt-https.rule=Host(`xkb.744204541.xyz`) || PathPrefix(`/stt`)"
      - "traefik.http.routers.stt-https.entrypoints=websecure"
      - "traefik.http.routers.stt-https.tls=true"
      - "traefik.http.services.stt.loadbalancer.server.port=9000"
      # ğŸ”¥ è½¬å‘åˆ°å®¹å™¨å†…çš„è¯·æ±‚å»é™¤å‰ç¼€ + æ·»åŠ è®¤è¯
      - "traefik.http.routers.stt-https.middlewares=stt-stripprefix,protected-api"
      - "traefik.http.middlewares.stt-stripprefix.stripprefix.prefixes=/stt"




#===============================================
#           async_cosyvocieæœåŠ¡
#===============================================
  tts-service:
    build: 
      context: ./CosyVoice  # ç»å¯¹è·¯å¾„åˆ°CosyVoiceç›®å½•
      dockerfile: Dockerfile
    container_name: TTS_55002
    ports:
      - "50000:50000"  # gRPCç«¯å£
      - "55002:9000"   # FastAPIç«¯å£
    environment:
      - PYTHONUNBUFFERED=1
      - CUDA_VISIBLE_DEVICES=7  # GPUè®¾å¤‡7
      - FASTAPI_ROOT_PATH=/tts  # è®¾ç½®FastAPIæ ¹è·¯å¾„
    volumes:
      # æ¨¡å‹æ–‡ä»¶æŒ‚è½½
      - ./CosyVoice/pretrained_models/CosyVoice2-0.5B:/app/models/CosyVoice2-0.5B
      # éŸ³é¢‘è¾“å‡ºç›®å½•
      - ./CosyVoice/async_cosyvoice/runtime/async_grpc/audio_output:/app/audio_output
      - ./CosyVoice/async_cosyvoice/runtime/async_grpc/shared-data:/app/shared
      # æ–°å¢ï¼šqc16kéŸ³é¢‘æ–‡ä»¶æŒ‚è½½
      - ./CosyVoice/my_asset/qc16k.wav:/app/assets/qc16k.wav
    command: >
      /bin/bash -c "
        cd /app/async_cosyvoice/runtime/async_grpc && 
        chmod +x start_services.sh && 
        ./start_services.sh && 
        tail -f /dev/null
      "
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 300s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0','1','2','3','4','5','6','7']  # GPUè®¾å¤‡7
              capabilities: [gpu]
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      # === 1. HTTPS è·¯ç”±ï¼šå®é™…å¤„ç†è¯·æ±‚ ===
      - "traefik.http.routers.tts-https.rule=Host(`xkb.744204541.xyz`) || PathPrefix(`/tts`)"
      - "traefik.http.routers.tts-https.entrypoints=websecure"
      - "traefik.http.routers.tts-https.tls=true"
      - "traefik.http.services.tts.loadbalancer.server.port=9000"
      # ğŸ”¥ è½¬å‘åˆ°å®¹å™¨å†…çš„è¯·æ±‚å»é™¤å‰ç¼€ + æ·»åŠ è®¤è¯
      - "traefik.http.routers.tts-https.middlewares=tts-stripprefix,protected-api"
      - "traefik.http.middlewares.tts-stripprefix.stripprefix.prefixes=/tts"

  # SGLang æ¨¡å‹æ¨ç†æœåŠ¡ - åŸºäºolmOCRæ¨¡å‹
  sglang-service:
    # æ„å»ºä½ çš„ Docker é•œåƒ
    build:
      context: ./sglang_service
      dockerfile: Dockerfile
    image: my-sglang-service:latest
    container_name: VLM_SGLANG_30024

    ports:
      - "30024:30024"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['2']
              capabilities: [gpu]

    volumes:
      - /home/xkb2/Desktop/QY/olmocr/model/olmOCR-7B-0225-preview:/app/model/olmOCR-7B-0225-preview

    # é‡å¯ç­–ç•¥ï¼Œå¯é€‰
    restart: unless-stopped
    networks:
      - ai-services

  # OCRä¸šåŠ¡é€»è¾‘æœåŠ¡ - åŸºäºOLMOCR API
  ocr-service:
    build: 
      context: ./olmocr
      dockerfile: Dockerfile
    image: olmocr-api:latest
    container_name: OCR_55004
    ports:
      - "55004:9000"
    environment:
      - PYTHONUNBUFFERED=1
      - OCR_PORT=9000
      - OCR_HOST=0.0.0.0
      # æ¨¡å‹å’Œç¼“å­˜é…ç½®
      - MODEL_NAME=./model/olmOCR-7B-0225-preview
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      # SGLangæœåŠ¡è¿æ¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
      - SGLANG_SERVER_URL=http://sglang-service:30024
      - SGLANG_SERVER_PORT=30024
      - APPLY_FILTER=false
      - HTTPS_PROXY=http://192.168.2.222:1080
      - HTTP_PROXY=http://192.168.2.222:1080
      - FASTAPI_ROOT_PATH=/ocr
    volumes:
      # å·¥ä½œç›®å½•å’Œæ•°æ®å…±äº«
      - ./shared-data:/app/shared
      - ./olmocr/uploads:/app/uploads
      - ./olmocr/results:/app/results
      - ./olmocr/temp:/app/temp
      # æ—¥å¿—å’Œç¼“å­˜
      - ./olmocr/logs:/app/logs
      - /root/.cache/huggingface:/root/.cache/huggingface
      # æœ¬åœ°æ¨¡å‹æŒ‚è½½
      - ./olmocr/model:/app/model:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/olmocr/"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s  # CUDAé•œåƒå¯åŠ¨æ—¶é—´ç¨é•¿
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    depends_on:
      - sglang-service  # ä¿æŒå¯¹SGLangçš„ä¾èµ–
    labels:
      - "traefik.enable=true"
      # === 1. HTTPS è·¯ç”±ï¼šå®é™…å¤„ç†è¯·æ±‚ ===
      - "traefik.http.routers.ocr-https.rule=Host(`xkb.744204541.xyz`) || PathPrefix(`/ocr`)"
      - "traefik.http.routers.ocr-https.entrypoints=websecure"
      - "traefik.http.routers.ocr-https.tls=true"
      - "traefik.http.services.ocr.loadbalancer.server.port=9000"
      # ğŸ”¥ è½¬å‘åˆ°å®¹å™¨å†…çš„è¯·æ±‚å»é™¤å‰ç¼€ + æ·»åŠ è®¤è¯
      - "traefik.http.routers.ocr-https.middlewares=ocr-stripprefix,protected-api"
      - "traefik.http.middlewares.ocr-stripprefix.stripprefix.prefixes=/ocr"

  # æ–°å¢MySQLæœåŠ¡ - åŸºäºç”¨æˆ·Dockerå‘½ä»¤é…ç½®
  mysql-db:
    image: mysql:9.3
    container_name: mysql_db
    ports:
      - "3306:3306"  # ä¿®æ”¹ä¸»æœºç«¯å£é¿å…å†²çª
    privileged: true
    environment:
      MYSQL_ROOT_PASSWORD: qwe123asd
    volumes:
      - /data/mysql/data:/var/lib/mysql
      - /data/mysql/log:/var/log/mysql
      - /etc/localtime:/etc/localtime
      - /data/mysql/my.cnf:/etc/mysql/my.cnf
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-pqwe123asd"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # Userç”¨æˆ·ç®¡ç†æœåŠ¡
  user-service:
    build: 
      context: ./user-service
      dockerfile: Dockerfile
    container_name: USER_55003
    ports:
      - "55003:9000"
    environment:
      - PYTHONUNBUFFERED=1
      - DB_HOST=mysql-db
      - DB_USER=root
      - DB_PASSWORD=qwe123asd
      - DB_NAME=CHAT
      - FASTAPI_ROOT_PATH=/user
    volumes:
      - ./shared-data:/app/shared
      - ./user-service/logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/get_all_users/", "-H", "X-API-Key: xkbai"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    depends_on:
      mysql-db:
        condition: service_healthy
    labels:   
      - "traefik.enable=true"
      - "traefik.http.routers.user-https.rule=PathPrefix(`/user`)"
      - "traefik.http.routers.user-https.entrypoints=websecure"
      - "traefik.http.routers.user-https.tls=true"
      - "traefik.http.services.user.loadbalancer.server.port=9000"
      - "traefik.http.routers.user-https.middlewares=user-stripprefix"
      - "traefik.http.middlewares.user-stripprefix.stripprefix.prefixes=/user"

  # MD2PDF Markdownè½¬PDFæœåŠ¡
  md2pdf-service:
    build: 
      context: ./md2pdf-service
      dockerfile: Dockerfile
    container_name: MD2PDF_55005
    ports:
      - "55005:9000"
    environment:
      - PYTHONUNBUFFERED=1
      - IMAGE_ROOT_DIR=/app/shared
      - PORT=9000
      - HOST=0.0.0.0
      # è®¾ç½®æ—¶åŒº
      - TZ=Asia/Shanghai
      # ç¦ç”¨ä»£ç†ç”¨äºå®¹å™¨å†…éƒ¨é€šä¿¡
      - http_proxy=
      - https_proxy=
      - HTTP_PROXY=
      - HTTPS_PROXY=
      - FASTAPI_ROOT_PATH=/md2pdf
    volumes:
      - ./shared-data:/app/shared
      - ./md2pdf-service/logs:/app/logs
      - ./md2pdf-service/storage:/app/storage
      # å¦‚æœéœ€è¦è®¿é—®ç³»ç»Ÿå­—ä½“
      - /usr/share/fonts:/usr/share/fonts:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.md2pdf-https.rule=PathPrefix(`/md2pdf`)"
      - "traefik.http.routers.md2pdf-https.entrypoints=websecure"
      - "traefik.http.routers.md2pdf-https.tls=true"
      - "traefik.http.services.md2pdf.loadbalancer.server.port=9000"
      - "traefik.http.routers.md2pdf-https.middlewares=md2pdf-stripprefix"
      - "traefik.http.middlewares.md2pdf-stripprefix.stripprefix.prefixes=/md2pdf"

  # APIç½‘å…³æœåŠ¡
  auth:
    build:
      context: ./auth
      dockerfile: Dockerfile
    container_name: AUTH
    ports:
      - "54000:9000"
    environment:
      - PYTHONUNBUFFERED=1
      - FASTAPI_ROOT_PATH=/auth
    volumes:
      - ./shared-data:/app/shared
      - ./api-gateway-service/logs:/app/logs
    restart: unless-stopped
    # ç¦ç”¨Dockerfileä¸­å®šä¹‰çš„å¥åº·æ£€æŸ¥ï¼Œå› ä¸ºä¾èµ–çš„æœåŠ¡æ£€æŸ¥ä¼šå¯¼è‡´è¶…æ—¶
    healthcheck:
      disable: true
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.auth-https.rule=Host(`xkb.744204541.xyz`) || PathPrefix(`/auth`)"
      - "traefik.http.routers.auth-https.entrypoints=websecure"
      - "traefik.http.routers.auth-https.tls=true"
      - "traefik.http.services.auth.loadbalancer.server.port=9000"
      - "traefik.http.routers.auth-https.service=auth"
      # ğŸ”¥ è®¤è¯æœåŠ¡æœ¬èº«ä¸éœ€è¦è®¤è¯ï¼Œåªéœ€è¦CORS
      - "traefik.http.routers.auth-https.middlewares=auth-stripprefix,cors-headers"
      - "traefik.http.middlewares.auth-stripprefix.stripprefix.prefixes=/auth"

  api-gateway:
    build: 
      context: ./api-gateway-service
      dockerfile: Dockerfile
    container_name: API_GATEWAY_60443
    ports:
      - "60443:60443"
    environment:
      - PYTHONUNBUFFERED=1
      - STT_SERVICE_URL=http://STT_55001:9000
      - TTS_SERVICE_URL=http://TTS_55002:9000
      - OCR_SERVICE_URL=http://OCR_BUSINESS_55004:9000
      - SGLANG_SERVICE_URL=http://SGLANG_30024:30024
      - USER_SERVICE_URL=http://USER_55003:9000
      - VLM_SERVICE_URL=http://VLM_55004:9000
      - MD2PDF_SERVICE_URL=http://192.168.2.3:55000
      - LLM_SERVICE_URL=http://192.168.2.3:61080
      - XINFERENCE_SERVICE_URL=http://XINFERENCE_SERVER_9997:9997
      - EMBEDDING_SERVICE_URL=http://XINFERENCE_SERVER_9997:9997
      - RERANKER_SERVICE_URL=http://XINFERENCE_SERVER_9997:9997
      # SSLé…ç½®ç¯å¢ƒå˜é‡
      - SSL_ROOT_DIR=/app/ssl/cert
      - SSL_CERT_NAME=fullchain.cer
      - SSL_KEY_NAME=*.744204541.xyz.key
      - GATEWAY_PORT=60443
      - FASTAPI_ROOT_PATH=/api-gateway
    volumes:
      - ./shared-data:/app/shared
      - ./api-gateway-service/logs:/app/logs
      # SSLè¯ä¹¦æŒ‚è½½
      - /home/xkb2/ACME.sh/https/acme.sh/cert:/app/ssl/cert:ro
    restart: unless-stopped
    # ç¦ç”¨Dockerfileä¸­å®šä¹‰çš„å¥åº·æ£€æŸ¥ï¼Œå› ä¸ºä¾èµ–çš„æœåŠ¡æ£€æŸ¥ä¼šå¯¼è‡´è¶…æ—¶
    healthcheck:
      disable: true
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    # æš‚æ—¶ç§»é™¤æ‰€æœ‰ä¾èµ–ï¼Œè®©ç½‘å…³å¯ä»¥ç‹¬ç«‹å¯åŠ¨
    # depends_on:
      # - faster-whisper-stt
      # - melotts-tts
      # - user-service
      # - md2pdf-service
      # - xinference-service
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.gateway-https.rule=PathPrefix(`/api`)"
      - "traefik.http.routers.gateway-https.entrypoints=websecure"
      - "traefik.http.routers.gateway-https.tls=true"
      - "traefik.http.services.gateway.loadbalancer.server.port=9000"
      - "traefik.http.routers.gateway-https.middlewares=gateway-stripprefix"
      - "traefik.http.middlewares.gateway-stripprefix.stripprefix.prefixes=/api"

  milvus-service:
    build: 
      context: ./milvus_utils
      dockerfile: Dockerfile
    container_name: milvus-service
    ports:
      - "57300:9000"
    environment:
      - PYTHONUNBUFFERED=1
      - MILVUS_HOST=milvus-standalone
      - EMBEDDING_URL=http://xinference_service:9997/v1
      - FASTAPI_ROOT_PATH=/milvus
    volumes:
      - ./shared-data:/app/shared
    restart: unless-stopped
    # ç¦ç”¨Dockerfileä¸­å®šä¹‰çš„å¥åº·æ£€æŸ¥ï¼Œå› ä¸ºä¾èµ–çš„æœåŠ¡æ£€æŸ¥ä¼šå¯¼è‡´è¶…æ—¶
    healthcheck:
      disable: true
    networks:
      - ai-services
      - milvus-network
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    # æš‚æ—¶ç§»é™¤æ‰€æœ‰ä¾èµ–ï¼Œè®©ç½‘å…³å¯ä»¥ç‹¬ç«‹å¯åŠ¨
    depends_on:
      - milvus-minio
      - milvus-etcd
      - milvus-standalone
      - milvus-attu
      # - faster-whisper-stt
      # - melotts-tts
      # - user-service
      # - md2pdf-service
      # - xinference-service
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.milvus_service-https.rule=PathPrefix(`/api`)"
      - "traefik.http.routers.milvus_service-https.entrypoints=websecure"
      - "traefik.http.routers.milvus_service-https.tls=true"
      - "traefik.http.services.milvus_service.loadbalancer.server.port=9000"
      - "traefik.http.routers.milvus_service-https.middlewares=milvus_service-stripprefix"
      - "traefik.http.middlewares.milvus_service-stripprefix.stripprefix.prefixes=/api"

  # ====== æ–°å¢æœåŠ¡åŒºåŸŸ ======

  # Milvuså‘é‡æ•°æ®åº“ - etcd
  milvus-etcd:
    image: quay.io/coreos/etcd:v3.5.18
    container_name: milvus-etcd
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ./milvus/volumes/etcd:/etcd
    command: etcd -advertise-client-urls=http://milvus-etcd:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - ai-services
      - milvus-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # Milvuså‘é‡æ•°æ®åº“ - MinIO
  milvus-minio:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    container_name: milvus-minio
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "9001:9001"
      - "9002:9000"  # ä¿®æ”¹ç«¯å£é¿å…å†²çª
    volumes:
      - ./milvus/volumes/minio:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - ai-services
      - milvus-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # Milvuså‘é‡æ•°æ®åº“ - ä¸»æœåŠ¡
  milvus-standalone:
    image: milvusdb/milvus:v2.5.10
    container_name: milvus-standalone
    command: ["milvus", "run", "standalone"]
    security_opt:
      - seccomp:unconfined
    environment:
      ETCD_ENDPOINTS: milvus-etcd:2379
      MINIO_ADDRESS: milvus-minio:9000
    volumes:
      - ./milvus/volumes/milvus:/var/lib/milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - milvus-etcd
      - milvus-minio
    networks:
      - ai-services
      - milvus-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
        - "traefik.enable=true"
        - "traefik.http.routers.milvus-https.rule=PathPrefix(`/milvus`)"
        - "traefik.http.routers.milvus-https.entrypoints=websecure"
        - "traefik.http.routers.milvus-https.tls=true"
        - "traefik.http.services.milvus.loadbalancer.server.port=9091"
        - "traefik.http.routers.milvus-https.middlewares=milvus-stripprefix"
        - "traefik.http.middlewares.milvus-stripprefix.stripprefix.prefixes=/milvus"

  # Milvusç®¡ç†ç•Œé¢
  milvus-attu:
    image: zilliz/attu:latest
    container_name: milvus-attu
    environment:
      MILVUS_URL: milvus-standalone:19530
    ports:
      - "3001:3000"
    depends_on:
      - milvus-standalone
    networks:
      - ai-services
      - milvus-network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.attu-https.rule=PathPrefix(`/attu`)"
      - "traefik.http.routers.attu-https.entrypoints=websecure"
      - "traefik.http.routers.attu-https.tls=true"
      - "traefik.http.services.attu.loadbalancer.server.port=3000"
      - "traefik.http.routers.attu-https.middlewares=attu-stripprefix"
      - "traefik.http.middlewares.attu-stripprefix.stripprefix.prefixes=/attu"

  # Redisç¼“å­˜æœåŠ¡ - è¿ç§»è‡ªåŸé¡¹ç›®
  redis:
    image: redis:latest
    container_name: redis
    restart: always
    networks:
      - ai-services
      - newapi-network
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # MySQLæ•°æ®åº“ - è¿ç§»è‡ªåŸé¡¹ç›®
  mysql:
    image: mysql:8.2
    container_name: mysql_newapi
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: 123456
      MYSQL_DATABASE: new-api
    volumes:
      - mysql_data:/var/lib/mysql
    # ports:
    #   - "3306:3306"  # If you want to access MySQL from outside Docker, uncomment
    networks:
      - ai-services
      - newapi-network
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # NewAPIæœåŠ¡
  new-api:
    image: calciumion/new-api:v0.8.7.1
    container_name: new-api
    restart: always
    command: --log-dir /app/logs
    ports:
      - "3000:3000"
    volumes:
      - ./data:/data
      - ./logs:/app/logs
    environment:
      - SQL_DSN=root:123456@tcp(mysql:3306)/new-api
      - REDIS_CONN_STRING=redis://redis
      - TZ=Asia/Shanghai
    #      - TIKTOKEN_CACHE_DIR=./tiktoken_cache
    #      - SESSION_SECRET=random_string
    #      - NODE_TYPE=slave
    #      - SYNC_FREQUENCY=60
    #      - FRONTEND_BASE_URL=https://openai.justsong.cn
    depends_on:
      - redis
      - mysql
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O - http://localhost:3000/api/status | grep -o '\"success\":\\s*true' | awk -F: '{print $$2}'"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-services
      - newapi-network
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.newapi-https.rule=PathPrefix(`/newapi`)"
      - "traefik.http.routers.newapi-https.entrypoints=websecure"
      - "traefik.http.routers.newapi-https.tls=true"
      - "traefik.http.services.newapi.loadbalancer.server.port=3000"
      - "traefik.http.routers.newapi-https.middlewares=newapi-stripprefix"
      - "traefik.http.middlewares.newapi-stripprefix.stripprefix.prefixes=/newapi"

  # vLLMæœåŠ¡å™¨ - Qwen3-30Bæ¨¡å‹
  vllm-server-qwen:
    image: vllm/vllm-openai:v0.9.1
    container_name: SLM_19001
    profiles:
      - vllm-docker
    ports:
      - "19001:19001"
    environment:
      - PYTHONUNBUFFERED=1
      - CUDA_VISIBLE_DEVICES=3
      - NVIDIA_VISIBLE_DEVICES=3
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      # ä½¿ç”¨ModelScopeé•œåƒæº
      - HF_ENDPOINT=https://hf-mirror.com
      - MODELSCOPE_CACHE=/root/.cache/modelscope
      # ç¦ç”¨ä¸€äº›å¯èƒ½å¯¼è‡´GPUæ£€æµ‹é—®é¢˜çš„ä¼˜åŒ–
      - VLLM_ATTENTION_BACKEND=FLASHINFER
      - VLLM_USE_TRITON_FLASH_ATTN=0
      - VLLM_NCCL_SO_PATH=/usr/lib/x86_64-linux-gnu/libnccl.so.2
      # NCCLé…ç½® - ä¿®å¤å¤šGPUé€šä¿¡é—®é¢˜ï¼ˆå•GPUå¯èƒ½ä¸éœ€è¦ï¼Œä½†ä¿æŒä¸€è‡´æ€§ï¼‰
      - NCCL_DEBUG=INFO
      - NCCL_IB_DISABLE=1
      - NCCL_P2P_DISABLE=1
      - NCCL_SHM_DISABLE=1
      - NCCL_SOCKET_IFNAME=lo
    volumes:
      # æ¨¡å‹ç¼“å­˜ç›®å½• - ä½¿ç”¨ç›´æ¥æ¨¡å‹è·¯å¾„
      - /home/xkb2/modelscope_models/Qwen/Qwen3-8B:/model
      # æ—¥å¿—ç›®å½•
      - ./logs/vllm-qwen:/app/logs
      - ./qwen3_nonthinking.jinja:/app/qwen3_nonthinking.jinja
    command: >
      --host 0.0.0.0
      --port 19001
      --gpu-memory-utilization 0.93
      --model /model
      --served-model-name slm
      --trust-remote-code
      --chat-template /app/qwen3_nonthinking.jinja
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1', '2', '3', '4', '5', '6', '7']
              capabilities: [gpu]
        limits:
          memory: 32G
          cpus: '8'
    shm_size: 8gb
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:19001/v1/models"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 300s  # 30Bæ¨¡å‹åŠ è½½æ—¶é—´ç›¸å¯¹è¾ƒçŸ­
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
    ipc: host  # å¯¹åº”å®˜æ–¹å‘½ä»¤çš„--ipc=host
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.slm-https.rule=PathPrefix(`/slm`)"
      - "traefik.http.routers.slm-https.entrypoints=websecure"
      - "traefik.http.routers.slm-https.tls=true"
      - "traefik.http.services.slm.loadbalancer.server.port=19001"
      - "traefik.http.routers.slm-https.middlewares=slm-stripprefix"
      - "traefik.http.middlewares.slm-stripprefix.stripprefix.prefixes=/slm"

  # vLLMæœåŠ¡å™¨ - Hunyuan-A52Bæ¨¡å‹ (2å¡ç‰ˆæœ¬)
  llm-server-hunyuan:
    image: vllm/vllm-openai:v0.9.2
    container_name: LLM_17001
    profiles:
      - vllm-docker
    ports:
      - "17001:17001"
    environment:
      - PYTHONUNBUFFERED=1
      - CUDA_VISIBLE_DEVICES=4,5
      - NVIDIA_VISIBLE_DEVICES=4,5
      # Hugging Faceé…ç½®
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      - HUGGING_FACE_HUB_TOKEN=<secret>
      # ä½¿ç”¨ModelScopeé•œåƒæºåŠ é€Ÿ
      - HF_ENDPOINT=https://hf-mirror.com
      - MODELSCOPE_CACHE=/root/.cache/modelscope
      - VLLM_USE_V1=0
      # NCCLé…ç½® - 2å¡é€šä¿¡ä¼˜åŒ–
      - NCCL_DEBUG=INFO
      - NCCL_IB_DISABLE=1
      - NCCL_P2P_DISABLE=0  # 2å¡é—´å¯ç”¨P2P
      - NCCL_SHM_DISABLE=0  # å¯ç”¨å…±äº«å†…å­˜
      - NCCL_SOCKET_IFNAME=lo
    volumes:
      # æŒ‚è½½Hunyuanè¾ƒå¤§ç‰ˆæœ¬æ¨¡å‹ç›®å½•
      - /home/xkb2/modelscope_models/Tencent-Hunyuan/Hunyuan-A13B-Instruct-GPTQ-Int4:/model
      - ~/.cache/huggingface:/root/.cache/huggingface
      # æ—¥å¿—ç›®å½•
      - ./logs/vllm-hunyuan-2gpu:/app/logs
    command: >
      --model /model
      --host 0.0.0.0
      --port 17001
      --gpu-memory-utilization 0.93
      --served-model-name llm
      --trust-remote-code
      --tensor-parallel-size 2
      --max-model-len 32768
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1', '2', '3', '4', '5', '6', '7']
              capabilities: [gpu]
        limits:
          memory: 48G
          cpus: '12'
    shm_size: 16gb
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:17001/v1/models"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 360s  # 2å¡æ¨¡å‹åŠ è½½æ—¶é—´ç¨é•¿
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "5"
    ipc: host
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.llm-https.rule=PathPrefix(`/llm`)"
      - "traefik.http.routers.llm-https.entrypoints=websecure"
      - "traefik.http.routers.llm-https.tls=true"
      - "traefik.http.services.llm.loadbalancer.server.port=17001"
      - "traefik.http.routers.llm-https.middlewares=llm-stripprefix"
      - "traefik.http.middlewares.llm-stripprefix.stripprefix.prefixes=/llm"

    # vLLMæœåŠ¡å™¨ - Qwen2.5-3B Tinyæ¨¡å‹
  tlm-server:
    image: vllm/vllm-openai:v0.9.2
    container_name: TLM_16001
    profiles:
      - vllm-docker
    ports:
      - "16001:16001"
    environment:
      - PYTHONUNBUFFERED=1
      - CUDA_VISIBLE_DEVICES=6
      - NVIDIA_VISIBLE_DEVICES=6
      # Hugging Faceé…ç½®
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      # ä½¿ç”¨ModelScopeé•œåƒæº
      - HF_ENDPOINT=https://hf-mirror.com
      - MODELSCOPE_CACHE=/root/.cache/modelscope
      # ä¼˜åŒ–å°æ¨¡å‹æ€§èƒ½
      - VLLM_ATTENTION_BACKEND=FLASHINFER
      - VLLM_USE_TRITON_FLASH_ATTN=1
    volumes:
      # æŒ‚è½½å°æ¨¡å‹ç›®å½•
      - /home/xkb2/modelscope_models/Qwen/Qwen3-0.6B:/model
      # æ—¥å¿—ç›®å½•
      - ./logs/vllm-tiny:/app/logs
      - ./qwen3_nonthinking.jinja:/app/qwen3_nonthinking.jinja
    command: >
      --host 0.0.0.0
      --port 16001
      --gpu-memory-utilization 0.8
      --model /model
      --served-model-name tlm
      --trust-remote-code
      --max-model-len 32768
      --enable-chunked-prefill
      --max-num-batched-tokens 8192
      --max-num-seqs 256
      --chat-template /app/qwen3_nonthinking.jinja
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1', '2', '3', '4', '5', '6', '7']
              capabilities: [gpu]
        limits:
          memory: 16G
          cpus: '4'
    shm_size: 4gb
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:16001/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s  # å°æ¨¡å‹åŠ è½½å¾ˆå¿«
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    ipc: host
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.tlm-https.rule=PathPrefix(`/tlm`)"
      - "traefik.http.routers.tlm-https.entrypoints=websecure"
      - "traefik.http.routers.tlm-https.tls=true"
      - "traefik.http.services.tlm.loadbalancer.server.port=16001"
      - "traefik.http.routers.tlm-https.middlewares=tlm-stripprefix"
      - "traefik.http.middlewares.tlm-stripprefix.stripprefix.prefixes=/tlm"

  # Xinference æœåŠ¡å™¨ (embedding + reranker)
  xinference-service:
    image: xprobe/xinference:latest
    container_name: XINFERENCE_9997
    ports:
      - "9997:9997" # Xinference çš„é»˜è®¤ç«¯å£
    environment:
      - XINFERENCE_HOME=/root/.xinference # Xinference æ•°æ®å’Œæ¨¡å‹ç¼“å­˜è·¯å¾„
      - PYTHONUNBUFFERED=1
      - CUDA_VISIBLE_DEVICES=0,1
      - NVIDIA_VISIBLE_DEVICES=0,1
      # ä½¿ç”¨ModelScopeé•œåƒæº
      - HF_ENDPOINT=https://hf-mirror.com
      - MODELSCOPE_CACHE=/root/.cache/modelscope
      - VLLM_LOGGING_LEVEL=DEBUG
    volumes:
      # æŒ‚è½½å®¿ä¸»æœºç›®å½•ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹æ–‡ä»¶ï¼Œé¿å…æ¯æ¬¡é‡å¯å®¹å™¨éƒ½é‡æ–°ä¸‹è½½
      - ./xinference_data:/root/.xinference
      # æ—¥å¿—ç›®å½•
      - ./logs/xinference:/app/logs
      # å¦‚æœä½ çš„æ¨¡å‹ç¼“å­˜åœ¨ Hugging Face é»˜è®¤è·¯å¾„ï¼Œå¯ä»¥æŒ‚è½½è¿™ä¸ªç›®å½•
      # - ~/.cache/huggingface:/root/.cache/huggingface
    command: >
      bash -c "
        xinference-local --host 0.0.0.0 --port 9997 &
        XINFERENCE_PID=$$!

        echo 'Waiting for Xinference service to start...'
        sleep 30

        for i in {1..10}; do
          if curl -f http://localhost:9997/v1/models 2>/dev/null; then
            echo 'Xinference service is ready!'
            break
          fi
          echo 'Waiting for Xinference service... attempt' $$i
          sleep 10
        done

        echo 'Launching embedding model...'
        xinference launch --model-name bge-large-zh-v1.5 --model-type embedding --model-uid bge-large-zh-v1.5 --model-engine vllm --replica 4 || echo 'Failed to launch embedding model'

        echo 'Launching reranker model...'
        xinference launch --model-name bge-reranker-v2-m3 --model-type rerank --model-uid bge-reranker-v2-m3 --gpu-idx 1 --replica 4 || echo 'Failed to launch reranker model'

        wait $$XINFERENCE_PID
      "
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]
        limits:
          memory: 16G
          cpus: '4'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9997/v1/models"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s  # Xinferenceéœ€è¦æ—¶é—´åŠ è½½æ¨¡å‹
    networks:
      - ai-services
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.xinference-https.rule=PathPrefix(`/xinference`)"
      - "traefik.http.routers.xinference-https.entrypoints=websecure"
      - "traefik.http.routers.xinference-https.tls=true"
      - "traefik.http.services.xinference.loadbalancer.server.port=9997"
      - "traefik.http.routers.xinference-https.middlewares=xinference-stripprefix"
      - "traefik.http.middlewares.xinference-stripprefix.stripprefix.prefixes=/xinference"
      

# ç½‘ç»œé…ç½®
networks:
  ai-services:
    driver: bridge
    name: ai-services
  milvus-network:
    driver: bridge
    name: milvus-network
  newapi-network:
    driver: bridge
    name: newapi-network

# å·é…ç½®
volumes:
  mysql_data:
    external: true
    name: new-api_mysql_data  # ä½¿ç”¨å·²å­˜åœ¨çš„å·
  shared-data:
    driver: local
    driver_opts:
      type: bind
      o: bind
      device: ./shared-data
      
  # æ¨¡å‹ç¼“å­˜ç›®å½•
  whisper-models:
    driver: local
    driver_opts:
      type: bind
      o: bind
      device: ./models/whisper

  # OCRæ¨¡å‹ç¼“å­˜ç›®å½•
  olmocr-models:
    driver: local
    driver_opts:
      type: bind
      o: bind
      device: ./models/olmocr

  # MySQLæ•°æ®åº“æ•°æ®ç›®å½•
  mysql-data:
    driver: local
    driver_opts:
      type: bind
      o: bind
      device: ./database/mysql-data

  # Prometheusæ•°æ®ç›®å½•
  prometheus-data:
    driver: local

  # Grafanaæ•°æ®ç›®å½•
  grafana-data:
    driver: local

  # UseræœåŠ¡æ—¥å¿—ç›®å½•
  user-logs:
    driver: local
    driver_opts:
      type: bind
      o: bind
      device: ./user-service/logs 