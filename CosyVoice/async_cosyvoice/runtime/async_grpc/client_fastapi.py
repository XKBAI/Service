# client_fastapi.py - æ ¹æ®utils.pyå®Œå…¨ä¿®å¤ç‰ˆ
import asyncio
from importlib import reload
import time
import tempfile
import os
from typing import List
from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
import soundfile as sf
import librosa
import grpc
from grpc import aio
import cosyvoice_pb2
import cosyvoice_pb2_grpc
import logging
import torch
import torchaudio

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="CosyVoice TTS Service with QC16K Voice", version="1.0.0")

# æ·»åŠ CORSæ”¯æŒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class TTSRequest(BaseModel):
    text: str
    speed: float = 1.0
    stream: bool = False
    format: str = ""

# === æ ¹æ®utils.pyä¿®å¤çš„éŸ³é¢‘å¤„ç†å‡½æ•° ===

def load_wav_for_server(wav_path: str, target_sr: int = 16000) -> np.ndarray:
    """åŠ è½½éŸ³é¢‘å¹¶è½¬æ¢ä¸ºserverç«¯æœŸæœ›çš„float32æ ¼å¼"""
    try:
        data, sample_rate = sf.read(wav_path, dtype='float32')
        
        if len(data.shape) > 1:
            data = np.mean(data, axis=1)
        
        if sample_rate != target_sr:
            data = librosa.resample(
                data,
                orig_sr=sample_rate,
                target_sr=target_sr,
                res_type='kaiser_fast'
            )
        
        # ç¡®ä¿æ•°æ®èŒƒå›´åœ¨[-1, 1]ï¼ˆfloat32æ ¼å¼ï¼‰
        data = np.clip(data, -1.0, 1.0)
        
        # ä¿æŒfloat32æ ¼å¼ï¼ˆè¿™æ˜¯serverç«¯æœŸæœ›çš„ï¼‰
        data = data.astype(np.float32)
        data = data.reshape(1, -1)  # (1, samples)
        
        logger.info(f"éŸ³é¢‘åŠ è½½æˆåŠŸ: shape={data.shape}, dtype={data.dtype}")
        return data
        
    except Exception as e:
        logger.error(f"éŸ³é¢‘åŠ è½½å¤±è´¥ {wav_path}: {str(e)}")
        raise

def convert_audio_ndarray_to_bytes_for_server(array: np.ndarray) -> bytes:
    """å°†numpyæ•°ç»„è½¬æ¢ä¸ºserverç«¯æœŸæœ›çš„float32 bytes"""
    # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32ï¼ˆserverç«¯æœŸæœ›çš„æ ¼å¼ï¼‰
    if array.dtype != np.float32:
        array = array.astype(np.float32)
    
    # ç¡®ä¿æ•°æ®èŒƒå›´åœ¨[-1, 1]
    array = np.clip(array, -1.0, 1.0)
    
    # ç¡®ä¿æ•°ç»„æ˜¯è¿ç»­çš„
    array = np.ascontiguousarray(array)
    
    if array.size == 0:
        raise ValueError("éŸ³é¢‘æ•°ç»„ä¸ºç©º")
    
    # è½¬æ¢ä¸ºbytesï¼ˆä¸serverç«¯çš„convert_audio_bytes_to_tensoråŒ¹é…ï¼‰
    audio_bytes = array.tobytes()
    
    logger.info(f"æ•°ç»„è½¬bytes: shape={array.shape}, dtype={array.dtype}, bytes_len={len(audio_bytes)}")
    return audio_bytes

def reconstruct_audio_from_server_response(audio_chunks: List[bytes]) -> torch.Tensor:
    """æ ¹æ®serverç«¯çš„convert_audio_tensor_to_bytesé‡å»ºéŸ³é¢‘"""
    try:
        all_audio_data = []
        
        for i, chunk in enumerate(audio_chunks):
            logger.info(f"å¤„ç†chunk {i}: {len(chunk)} bytes")
            
            # serverç«¯è¿”å›çš„æ˜¯float32æ ¼å¼ï¼ˆæ ¹æ®utils.pyç¬¬12è¡Œï¼‰
            audio_array = np.frombuffer(chunk, dtype=np.float32)
            
            if len(audio_array) == 0:
                logger.warning(f"Chunk {i} ä¸ºç©º")
                continue
                
            # è½¬æ¢ä¸ºtorch tensor
            audio_tensor = torch.from_numpy(audio_array).float()
            all_audio_data.append(audio_tensor)
            
            logger.info(f"Chunk {i} å¤„ç†å®Œæˆ: {len(audio_array)} samples")
        
        if not all_audio_data:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®")
        
        # åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
        final_audio = torch.cat(all_audio_data, dim=0)
        
        # é‡æ–°å¡‘å½¢ä¸º (1, samples) æ ¼å¼
        if final_audio.dim() == 1:
            final_audio = final_audio.unsqueeze(0)
        
        # ç¡®ä¿æ•°æ®èŒƒå›´æ­£ç¡®
        final_audio = torch.clamp(final_audio, -1.0, 1.0)
        
        duration = final_audio.shape[1] / 24000  # CosyVoiceé»˜è®¤é‡‡æ ·ç‡
        logger.info(f"éŸ³é¢‘é‡å»ºå®Œæˆ: shape={final_audio.shape}, æ—¶é•¿={duration:.2f}s")
        
        return final_audio
        
    except Exception as e:
        logger.error(f"éŸ³é¢‘é‡å»ºå¤±è´¥: {str(e)}")
        raise

# === gRPCå®¢æˆ·ç«¯ç±» ===

class CosyVoiceGRPCClient:
    def __init__(self, host="localhost", port=50000):
        self.host = host
        self.port = port
        self.qc16k_audio_bytes = None
        self.load_qc16k_audio()
        
    def load_qc16k_audio(self):
        """åŠ è½½qc16kéŸ³é¢‘æ–‡ä»¶å¹¶è½¬æ¢ä¸ºserverç«¯æœŸæœ›çš„æ ¼å¼"""
        qc16k_path = "/app/assets/qc16k.wav"
        try:
            # åŠ è½½ä¸ºfloat32æ ¼å¼ï¼ˆserverç«¯æœŸæœ›ï¼‰
            qc16k_audio = load_wav_for_server(qc16k_path, target_sr=16000)
            self.qc16k_audio_bytes = convert_audio_ndarray_to_bytes_for_server(qc16k_audio)
            logger.info(f"âœ… qc16kéŸ³è‰²åŠ è½½æˆåŠŸ: {qc16k_path}")
        except Exception as e:
            logger.error(f"âŒ qc16kéŸ³è‰²åŠ è½½å¤±è´¥: {e}")
            self.qc16k_audio_bytes = None

    def construct_qc16k_request(self, text: str, stream: bool = False, speed: float = 1.0, format: str = ""):
        """æ„å»ºqc16kè¯·æ±‚"""
        if self.qc16k_audio_bytes is None:
            raise HTTPException(status_code=500, detail="qc16kéŸ³è‰²æœªåŠ è½½æˆåŠŸ")
            
        request = cosyvoice_pb2.Request()
        request.tts_text = text
        request.stream = stream
        request.speed = speed
        request.text_frontend = True
        request.format = format  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä½¿ç”¨é»˜è®¤çš„float32æ ¼å¼
        
        cross_lingual_request = request.cross_lingual_request
        cross_lingual_request.prompt_audio = self.qc16k_audio_bytes
        
        logger.info(f"æ„å»ºqc16kè¯·æ±‚: text_len={len(text)}, audio_bytes_len={len(self.qc16k_audio_bytes)}")
        return request

    async def synthesize_with_qc16k(self, text: str, stream: bool = False, speed: float = 1.0, format: str = ""):
        """ä½¿ç”¨qc16kéŸ³è‰²åˆæˆè¯­éŸ³"""
        async with aio.insecure_channel(f"{self.host}:{self.port}") as channel:
            stub = cosyvoice_pb2_grpc.CosyVoiceStub(channel)
            
            grpc_request = self.construct_qc16k_request(text, stream, speed, format)
            
            audio_chunks = []
            start_time = time.time()
            
            try:
                logger.info(f"ğŸ¤ å¼€å§‹ä½¿ç”¨qc16kéŸ³è‰²åˆæˆ: {text[:50]}...")
                
                async for response in stub.Inference(grpc_request):
                    if response.tts_audio:
                        audio_chunks.append(response.tts_audio)
                        logger.info(f"æ”¶åˆ°éŸ³é¢‘chunk: {len(response.tts_audio)} bytes")
                    
                total_time = time.time() - start_time
                logger.info(f"âœ… qc16kéŸ³è‰²åˆæˆå®Œæˆï¼Œç”¨æ—¶: {total_time:.3f}s, å…±{len(audio_chunks)}ä¸ªchunks")
                
                return audio_chunks
                
            except grpc.RpcError as e:
                logger.error(f"gRPC error: {e.code()}: {e.details()}")
                raise HTTPException(status_code=500, detail=f"gRPC error: {e.details()}")
            except Exception as e:
                logger.error(f"Processing failed: {str(e)}")
                raise HTTPException(status_code=500, detail=f"Processing error: {str(e)}")

# åˆå§‹åŒ–gRPCå®¢æˆ·ç«¯
grpc_client = CosyVoiceGRPCClient()

# === FastAPIæ¥å£ ===

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "CosyVoice TTS Service with QC16K Voice - Utils.pyå®Œå…¨ä¿®å¤ç‰ˆ",
        "status": "running",
        "description": "æ ¹æ®utils.pyå®Œå…¨ä¿®å¤çš„ç‰ˆæœ¬ï¼Œä½¿ç”¨æ­£ç¡®çš„float32æ•°æ®æ ¼å¼",
        "qc16k_audio_loaded": grpc_client.qc16k_audio_bytes is not None,
        "qc16k_audio_size": len(grpc_client.qc16k_audio_bytes) if grpc_client.qc16k_audio_bytes else 0,
    }

@app.get("/tts/status")
async def tts_status():
    """TTSçŠ¶æ€æ£€æŸ¥ - åŒ¹é…ç½‘å…³æ¥å£"""
    return {"status": "healthy", "qc16k_loaded": grpc_client.qc16k_audio_bytes is not None}

@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "qc16k_loaded": grpc_client.qc16k_audio_bytes is not None}

@app.post("/tts/synthesize")
async def synthesize(request: TTSRequest):
    """è¯­éŸ³åˆæˆæ¥å£ï¼ˆä½¿ç”¨qc16kéŸ³è‰²ï¼‰- å®Œå…¨ä¿®å¤ç‰ˆ"""
    try:
        # è·å–éŸ³é¢‘chunks
        audio_chunks = await grpc_client.synthesize_with_qc16k(
            text=request.text,
            stream=request.stream,
            speed=request.speed,
            format=request.format
        )
        
        if not audio_chunks:
            raise HTTPException(status_code=500, detail="æ²¡æœ‰æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®")
        
        # é‡å»ºå®Œæ•´éŸ³é¢‘
        final_audio = reconstruct_audio_from_server_response(audio_chunks)
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav", dir="/app/audio_output")
        temp_file.close()
        
        # ä½¿ç”¨torchaudioä¿å­˜ï¼ˆä¸async_cosyvoiceæºç ä¸€è‡´ï¼‰
        torchaudio.save(temp_file.name, final_audio, 24000)
        
        return FileResponse(
            temp_file.name,
            media_type="audio/wav",
            filename="qc16k_synthesis_final.wav"
        )
        
    except Exception as e:
        logger.error(f"åˆæˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/test")
async def test_qc16k():
    """æµ‹è¯•qc16kéŸ³è‰²åˆæˆ"""
    try:
        audio_chunks = await grpc_client.synthesize_with_qc16k("ä½ å¥½ï¼Œè¿™æ˜¯å®Œå…¨ä¿®å¤çš„qc16kéŸ³è‰²æµ‹è¯•ï¼Œç°åœ¨åº”è¯¥æœ‰å£°éŸ³äº†ã€‚", stream=False, speed=1.0)
        
        final_audio = reconstruct_audio_from_server_response(audio_chunks)
        
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav", dir="/app/audio_output")
        temp_file.close()
        
        torchaudio.save(temp_file.name, final_audio, 24000)
        
        return FileResponse(
            temp_file.name,
            media_type="audio/wav",
            filename="qc16k_test_final.wav"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    root_path = os.getenv("FASTAPI_ROOT_PATH", "")
    uvicorn.run("client_fastapi:app", host="0.0.0.0", port=9000, reload=True, root_path=root_path)