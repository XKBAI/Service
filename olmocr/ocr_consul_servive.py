# OCR Service with Consul Integration - é˜Ÿåˆ—æ¨¡å¼å¹¶å‘ä¼˜åŒ–ç‰ˆæœ¬
import asyncio
import datetime
import json
import logging
import os
import shutil
import tempfile
import socket
import atexit
import consul
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Union

import uvicorn
from fastapi import BackgroundTasks, Depends, FastAPI, File, Form, HTTPException, Query, UploadFile, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from fastapi.routing import APIRouter
from pydantic import BaseModel, Field
from contextlib import asynccontextmanager

# å¯¼å…¥olmocr pipelineä¸­çš„å¿…è¦ç»„ä»¶
from olmocr.pipeline import (
    check_poppler_version,
    check_sglang_version,
    check_torch_gpu_available,
    convert_image_to_pdf_bytes,
    download_model,
    is_jpeg,
    is_png,
    process_pdf,
    sglang_server_ready,
    sglang_server_task,
)

# æœåŠ¡é…ç½®
DEFAULT_CONFIG = {
    "SERVICE_NAME": "ocr-service",
    "SERVICE_ID": "ocr-service-001",
    "SERVICE_PORT": 47003,  # é¿å…ç«¯å£å†²çª
    "CONSUL_HOST": "127.0.0.1",
    "CONSUL_PORT": 8500,
    "HEALTH_CHECK_INTERVAL": "10s",
    "HEALTH_CHECK_TIMEOUT": "5s",
    "HEALTH_CHECK_TTL": "30s",
    "MAX_CONCURRENT_TASKS": 100,
    "MAX_PARALLEL_PROCESSING": 3,
}

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger("olmocr-consul-api")
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s"))
logger.addHandler(handler)

# å…¨å±€å˜é‡
UPLOAD_DIR = Path("./uploads")
RESULTS_DIR = Path("./results")
MODEL_NAME = "./model/olmOCR-7B-0225-preview"

# å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
UPLOAD_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)

# å…¨å±€å˜é‡
concurrency_semaphore = None
task_queue = asyncio.Queue()
processing_tasks = {}
sglang_server_task_obj = None
jobs = {}

class OCRConsulService:
    """OCRå¾®æœåŠ¡çš„Consulé›†æˆç±»"""
    
    def __init__(self, config: dict = None):
        self.config = {**DEFAULT_CONFIG, **(config or {})}
        self.service_name = self.config["SERVICE_NAME"]
        self.service_id = self.config["SERVICE_ID"]
        self.service_port = self.config["SERVICE_PORT"]
        self.service_address = self._get_local_ip()
        
        # åˆå§‹åŒ–Consulå®¢æˆ·ç«¯
        try:
            self.client = consul.Consul(
                host=self.config["CONSUL_HOST"],
                port=self.config["CONSUL_PORT"]
            )
            logger.info(f"âœ… Consulå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ: {self.config['CONSUL_HOST']}:{self.config['CONSUL_PORT']}")
        except Exception as e:
            logger.error(f"âŒ Consulå®¢æˆ·ç«¯è¿æ¥å¤±è´¥: {e}")
            self.client = None
    
    def _get_local_ip(self) -> str:
        """è·å–æœ¬æœºIPåœ°å€"""
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            ip = s.getsockname()[0]
            s.close()
            return ip
        except Exception:
            return "127.0.0.1"
    
    def register_service(self) -> bool:
        """æ³¨å†ŒæœåŠ¡åˆ°Consul"""
        if not self.client:
            print("âš ï¸  Consulå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æœåŠ¡æ³¨å†Œ")
            return False
        
        try:
            # å¥åº·æ£€æŸ¥é…ç½®
            health_check = consul.Check.http(
                url=f"http://{self.service_address}:{self.service_port}/health",
                interval=self.config["HEALTH_CHECK_INTERVAL"],
                timeout=self.config["HEALTH_CHECK_TIMEOUT"],
                deregister=True
            )
            
            # æœåŠ¡æ ‡ç­¾
            tags = [
                'ocr',
                'text-recognition',
                'pdf-processing',
                'ai-service',
                f'version-1.0',
                f'port-{self.service_port}',
                'fastapi',
                'olmocr'
            ]
            
            # æ³¨å†ŒæœåŠ¡
            self.client.agent.service.register(
                name=self.service_name,
                service_id=self.service_id,
                address=self.service_address,
                port=self.service_port,
                tags=tags,
                check=health_check
            )
            
            logger.info(f"âœ… æœåŠ¡æ³¨å†ŒæˆåŠŸ: {self.service_name} @ {self.service_address}:{self.service_port}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æœåŠ¡æ³¨å†Œå¤±è´¥: {e}")
            return False
    
    def deregister_service(self) -> bool:
        """æ³¨é”€æœåŠ¡"""
        if not self.client:
            return False
        
        try:
            self.client.agent.service.deregister(self.service_id)
            logger.info(f"âœ… æœåŠ¡æ³¨é”€æˆåŠŸ: {self.service_id}")
            return True
        except Exception as e:
            logger.error(f"âŒ æœåŠ¡æ³¨é”€å¤±è´¥: {e}")
            return False
    
    def get_service_info(self) -> dict:
        """è·å–æœåŠ¡ä¿¡æ¯"""
        return {
            "service_name": self.service_name,
            "service_id": self.service_id,
            "service_address": self.service_address,
            "service_port": self.service_port,
            "consul_connected": self.client is not None
        }

# å…¨å±€æœåŠ¡å®ä¾‹
ocr_service = OCRConsulService()

# æŸ¥æ‰¾å¯ç”¨ç«¯å£å‡½æ•°
def find_available_port(start_port=30024, max_attempts=100):
    """æŸ¥æ‰¾å¯ç”¨ç«¯å£ï¼Œä»start_portå¼€å§‹å°è¯•"""
    for port in range(start_port, start_port + max_attempts):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('', port))
                return port
        except OSError:
            continue
    return None

# æŸ¥æ‰¾å¯ç”¨çš„SGLangæœåŠ¡å™¨ç«¯å£
SGLANG_SERVER_PORT = find_available_port(30024)
if not SGLANG_SERVER_PORT:
    raise RuntimeError("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„SGLangæœåŠ¡å™¨ç«¯å£")

# APIè®¾ç½®çš„é…ç½®æ¨¡å‹
class OLMOCRConfig(BaseModel):
    model: str = Field(default=MODEL_NAME, description="Model to use for OCR")
    model_max_context: int = Field(default=8192, description="Maximum context length for the model")
    model_chat_template: str = Field(default="qwen2-vl", description="Chat template to use")
    target_longest_image_dim: int = Field(default=1024, description="Target longest dimension for rendered images")
    target_anchor_text_len: int = Field(default=6000, description="Maximum anchor text length")
    max_page_retries: int = Field(default=8, description="Maximum number of retries per page")
    max_page_error_rate: float = Field(default=0.004, description="Maximum allowable page error rate")
    apply_filter: bool = Field(default=True, description="Apply PDF filtering")
    port: int = Field(default=SGLANG_SERVER_PORT, description="Port for SGLang server")

# ä½œä¸šçŠ¶æ€æšä¸¾
class JobStatus(str, Enum):
    PENDING = "pending"
    QUEUED = "queued"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

# ä½œä¸šæ¨¡å‹
class Job(BaseModel):
    id: str
    filename: str
    status: JobStatus = JobStatus.PENDING
    result_path: Optional[str] = None
    error: Optional[str] = None
    created_at: str = Field(default_factory=lambda: datetime.datetime.now().isoformat())
    queue_position: Optional[int] = None

# OCRç»“æœå“åº”æ¨¡å‹
class OCRResultResponse(BaseModel):
    job_id: str = Field(description="ä½œä¸šID")
    status: str = Field(description="ä½œä¸šçŠ¶æ€")
    text: str = Field(description="OCRè¯†åˆ«ç»“æœæ–‡æœ¬ï¼ŒæœªæˆåŠŸæ—¶ä¸ºç©ºå­—ç¬¦ä¸²")

# ç”Ÿå‘½å‘¨æœŸç®¡ç†
@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶
    global concurrency_semaphore, sglang_server_task_obj
    
    logger.info("ğŸš€ å¯åŠ¨OCRå¾®æœåŠ¡...")
    
    # æ³¨å†ŒæœåŠ¡åˆ°Consul
    if ocr_service.register_service():
        logger.info("âœ… æœåŠ¡å·²æ³¨å†Œåˆ°Consul")
    else:
        logger.warning("âš ï¸  æœåŠ¡æ³¨å†Œåˆ°Consulå¤±è´¥ï¼ŒæœåŠ¡ä»ä¼šå¯åŠ¨")
    
    try:
        # æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
        check_poppler_version()
        check_sglang_version()
        
        # åˆå§‹åŒ–å¹¶å‘æ§åˆ¶
        concurrency_semaphore = asyncio.Semaphore(DEFAULT_CONFIG["MAX_PARALLEL_PROCESSING"])
        
        # å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨
        for _ in range(DEFAULT_CONFIG["MAX_CONCURRENT_TASKS"]):
            asyncio.create_task(task_processor())
        
        # å¯åŠ¨æ¨¡å‹æœåŠ¡å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        config = OLMOCRConfig()
        args = Args(config)
        
        logger.info(f"âœ… OCRå¾®æœåŠ¡å¯åŠ¨æˆåŠŸ - ç«¯å£: {ocr_service.service_port}")
        
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        ocr_service.deregister_service()
        raise
    
    yield  # æœåŠ¡è¿è¡Œä¸­
    
    # å…³é—­æ—¶
    logger.info("ğŸ›‘ æ­£åœ¨å…³é—­OCRå¾®æœåŠ¡...")
    
    # æ³¨é”€æœåŠ¡
    if ocr_service.deregister_service():
        logger.info("âœ… æœåŠ¡å·²ä»Consulæ³¨é”€")
    
    # å–æ¶ˆä»»åŠ¡
    if sglang_server_task_obj:
        sglang_server_task_obj.cancel()
    
    logger.info("âœ… OCRå¾®æœåŠ¡å·²å…³é—­")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="OCRå¾®æœåŠ¡",
    description="åŸºäºOLMOCRçš„æ–‡æ¡£è¯†åˆ«å¾®æœåŠ¡ï¼Œæ”¯æŒConsulæœåŠ¡å‘ç°",
    version="1.0.0",
    lifespan=lifespan
)

# ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆ›å»ºè·¯ç”±
ocr_router = APIRouter(prefix="/ocr", tags=["OCR"])

# Argsç±»
class Args:
    def __init__(self, config: OLMOCRConfig):
        self.model = config.model
        self.model_max_context = config.model_max_context
        self.model_chat_template = config.model_chat_template
        self.target_longest_image_dim = config.target_longest_image_dim
        self.target_anchor_text_len = config.target_anchor_text_len
        self.max_page_retries = config.max_page_retries
        self.max_page_error_rate = config.max_page_error_rate
        self.apply_filter = config.apply_filter
        self.port = config.port
        self.workspace = str(RESULTS_DIR)
        self.workers = 1

async def get_config() -> OLMOCRConfig:
    return OLMOCRConfig()

# é˜Ÿåˆ—å¤„ç†ç›¸å…³å‡½æ•°
async def task_processor():
    """å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡"""
    logger.info("ä»»åŠ¡å¤„ç†å™¨å¯åŠ¨")
    
    while True:
        try:
            job_id = await task_queue.get()
            update_queue_positions()
            
            job = jobs.get(job_id)
            if not job or job.status == JobStatus.FAILED:
                task_queue.task_done()
                continue
            
            job.status = JobStatus.PROCESSING
            job.queue_position = None
            
            async with concurrency_semaphore:
                logger.info(f"å¤„ç†ä½œä¸š {job_id}")
                await process_job(job_id)
                
        except Exception as e:
            logger.exception(f"å¤„ç†ä½œä¸š {job_id} æ—¶å‡ºé”™: {e}")
            if job_id in jobs:
                jobs[job_id].status = JobStatus.FAILED
                jobs[job_id].error = str(e)
        finally:
            task_queue.task_done()

def update_queue_positions():
    """æ›´æ–°é˜Ÿåˆ—ä¸­æ‰€æœ‰ä½œä¸šçš„ä½ç½®"""
    queued_jobs = [job_id for job_id, job in jobs.items() if job.status == JobStatus.QUEUED]
    for position, job_id in enumerate(queued_jobs, 1):
        if job_id in jobs:
            jobs[job_id].queue_position = position

async def process_job(job_id: str):
    """å¤„ç†ä½œä¸šçš„ä¸»å‡½æ•°"""
    job = jobs[job_id]
    file_path = UPLOAD_DIR / f"{job_id}_{job.filename}"
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°ä¸Šä¼ çš„æ–‡ä»¶: {file_path}")
    
    config = await get_config()
    args = Args(config)
    
    job_result_dir = RESULTS_DIR / job_id
    job_result_dir.mkdir(exist_ok=True)
    
    worker_id = 0
    pdf_orig_path = str(file_path)
    
    result = await process_pdf(args, worker_id, pdf_orig_path)
    
    if result is None:
        raise Exception("PDFå¤„ç†å¤±è´¥æˆ–è¢«è¿‡æ»¤æ‰")
    
    result_path = job_result_dir / "result.json"
    with open(result_path, "w") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    jobs[job_id].status = JobStatus.COMPLETED
    jobs[job_id].result_path = str(result_path)
    logger.info(f"ä½œä¸š {job_id} å·²å®Œæˆ")

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    try:
        service_info = ocr_service.get_service_info()
        queue_info = {
            "queued_jobs": len([j for j in jobs.values() if j.status == JobStatus.QUEUED]),
            "processing_jobs": len([j for j in jobs.values() if j.status == JobStatus.PROCESSING])
        }
        
        return {
            "status": "healthy",
            "timestamp": datetime.datetime.now().isoformat(),
            "service": service_info,
            "queue": queue_info,
            "version": "1.0.0"
        }
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=503, detail="Service unhealthy")

# æœåŠ¡ä¿¡æ¯ç«¯ç‚¹
@app.get("/info")
async def service_info():
    """è·å–æœåŠ¡ä¿¡æ¯"""
    return {
        "service": ocr_service.get_service_info(),
        "config": DEFAULT_CONFIG,
        "endpoints": {
            "/health": "å¥åº·æ£€æŸ¥",
            "/info": "æœåŠ¡ä¿¡æ¯",
            "/ocr/process": "å¤„ç†æ–‡æ¡£",
            "/ocr/jobs/{job_id}": "è·å–ä½œä¸šçŠ¶æ€",
            "/ocr/results/{job_id}": "è·å–ä½œä¸šç»“æœ"
        }
    }

# OCRè·¯ç”±
@ocr_router.get("/")
async def ocr_root():
    """OCRæœåŠ¡æ ¹ç«¯ç‚¹"""
    return {
        "message": "OCRå¾®æœåŠ¡æ­£åœ¨è¿è¡Œ",
        "version": "1.0.0",
        "service_id": ocr_service.service_id
    }

@ocr_router.post("/process", response_model=Job)
async def process_file(
    file: UploadFile = File(...),
    config: OLMOCRConfig = Depends(get_config)
):
    """ä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£æ–‡ä»¶"""
    if not file.filename.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg')):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ä»…æ”¯æŒPDFå’Œå›¾åƒæ–‡ä»¶ï¼ˆPNGã€JPGï¼‰"
        )
    
    import uuid
    job_id = str(uuid.uuid4())
    file_path = UPLOAD_DIR / f"{job_id}_{file.filename}"
    
    try:
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}"
        )
    
    job = Job(id=job_id, filename=file.filename, status=JobStatus.QUEUED)
    jobs[job_id] = job
    
    await task_queue.put(job_id)
    update_queue_positions()
    
    return job

@ocr_router.get("/jobs/{job_id}", response_model=Job)
async def get_job(job_id: str):
    """è·å–ä½œä¸šçŠ¶æ€"""
    if job_id not in jobs:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"æœªæ‰¾åˆ°ä½œä¸š {job_id}"
        )
    return jobs[job_id]

@ocr_router.get("/results/{job_id}", response_model=OCRResultResponse)
async def get_results(job_id: str):
    """è·å–ä½œä¸šç»“æœ"""
    if job_id not in jobs:
        return OCRResultResponse(job_id=job_id, status="not_found", text="")
    
    job = jobs[job_id]
    
    if job.status == JobStatus.COMPLETED:
        if job.result_path and os.path.exists(job.result_path):
            try:
                with open(job.result_path, 'r', encoding='utf-8') as f:
                    result_data = json.load(f)
                    text_content = result_data.get('text', '')
                    return OCRResultResponse(
                        job_id=job_id,
                        status="completed",
                        text=text_content
                    )
            except Exception as e:
                logger.error(f"è¯»å–ä½œä¸š {job_id} ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
                return OCRResultResponse(job_id=job_id, status="result_file_error", text="")
        else:
            return OCRResultResponse(job_id=job_id, status="result_file_missing", text="")
    
    return OCRResultResponse(
        job_id=job_id,
        status=job.status.value,
        text=""
    )

@ocr_router.get("/status")
async def service_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    queue_info = {
        "queued": len([j for j in jobs.values() if j.status == JobStatus.QUEUED]),
        "processing": len([j for j in jobs.values() if j.status == JobStatus.PROCESSING]),
        "completed": len([j for j in jobs.values() if j.status == JobStatus.COMPLETED]),
        "failed": len([j for j in jobs.values() if j.status == JobStatus.FAILED])
    }
    
    return {
        "service": ocr_service.get_service_info(),
        "queue": queue_info,
        "total_jobs": len(jobs)
    }

# æ³¨å†Œè·¯ç”±
app.include_router(ocr_router)

# ç¨‹åºé€€å‡ºæ—¶æ¸…ç†
def cleanup():
    """ç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°"""
    logger.info("æ­£åœ¨æ¸…ç†èµ„æº...")
    ocr_service.deregister_service()

atexit.register(cleanup)

if __name__ == "__main__":
    import signal
    
    def handle_exit(signum, frame):
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡é€€å‡º...")
        cleanup()
    
    signal.signal(signal.SIGINT, handle_exit)
    signal.signal(signal.SIGTERM, handle_exit)
    
    logger.info(f"ğŸš€ å¯åŠ¨OCRå¾®æœåŠ¡ï¼Œç«¯å£: {ocr_service.service_port}")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=ocr_service.service_port,
        log_level="info",
        timeout_keep_alive=120,
        timeout_graceful_shutdown=30
    )